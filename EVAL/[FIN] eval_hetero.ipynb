{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This file evaluates the heterogeneous GNN models using a regression and random forest classifier. It uses the embeddings from the heterogeneous GNN models to classify newspapers as Republican or Democrat, and prints and exports the results."],"metadata":{"id":"RjuT0gimJhAQ"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"squIICf_GOc5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDWykDd3f2cL"},"outputs":[],"source":["# Imports\n","import pickle\n","from google.colab import drive\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd\n","import torch\n","import glob\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_curve, auc\n","from matplotlib import pyplot as plt\n","\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/cs224w_project')"]},{"cell_type":"code","source":["\"\"\"\n","Merge graph embeddings with ground truths.\n","\"\"\"\n","def create_merged_dataset(path, topic, decade):\n","  hetero_embeds = torch.load(path, weights_only=True)\n","  hetero_embeds = hetero_embeds['newspaper']\n","  ground_truths = pd.read_pickle(f\"karsen_redo/DATA/clean_ground_truths.pkl\")\n","  newspaper_indices = pd.read_pickle(f\"karsen_redo/HETEROGNN/newspaper_node_index-{decade}-{decade+10}-{topic}.pkl\")\n","  # Convert tensor to DataFrame\n","  embeds_array = hetero_embeds.numpy() if isinstance(hetero_embeds, torch.Tensor) else hetero_embeds\n","\n","  # Create a DataFrame for embeddings\n","  embeds_df = pd.DataFrame(embeds_array)\n","  embeds_df = embeds_df.rename_axis('index').reset_index()\n","\n","  # Convert newspaper_indices to a DataFrame\n","  indices_df = pd.DataFrame(list(newspaper_indices.items()), columns=['outlet_name', 'index'])\n","  merged_indices_embeds = pd.merge(indices_df, embeds_df, on='index')\n","  merged_indices_embeds['outlet_name'] = merged_indices_embeds['outlet_name'].astype(str)\n","\n","  # Merge with ground_truths on outlet_name to get the label\n","  final_dataset = pd.merge(merged_indices_embeds, ground_truths, on='outlet_name')\n","  return final_dataset\n","\n","\"\"\"\n","Fit a regression model on the graph embeddings at path, for a given topic and decade.\n","Return a results dictionary with metrics saved.\n","\"\"\"\n","def regression_hetgnn(path, topic, decade, result={'hyperparameters': {}, 'model': ''}):\n","  df = create_merged_dataset(path, topic, decade)\n","  print(df)\n","  X = df.drop(columns=['outlet_name', 'label', 'index'])\n","  y = df['label']\n","\n","  scaler = StandardScaler()\n","  X = scaler.fit_transform(X)\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=126)\n","  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.222, random_state=126)\n","  param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],  # regularization strength\n","}\n","  # REGRESSION\n","  model = LogisticRegression(max_iter=1000, class_weight='balanced') # tol=1e-4, max_iter=1000\n","  grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5) # , n_jobs=-1\n","  grid_search.fit(X_train, y_train)\n","\n","  best_params = grid_search.best_params_\n","  print(\"REGRESSION\\n\")\n","  print(\"------------------------\")\n","  print(\"Best hyperparameters:\", best_params)\n","\n","  best_model = grid_search.best_estimator_\n","\n","  best_model = model.fit(X_train, y_train)\n","\n","  y_val_pred = best_model.predict(X_val)\n","  val_accuracy = accuracy_score(y_val, y_val_pred)\n","  print(\"Validation Accuracy:\", val_accuracy)\n","  print(\"Validation Classification Report:\")\n","  report_val = classification_report(y_val, y_val_pred)\n","  print(report_val)\n","  roc_auc_val = roc_auc_score(y_val, best_model.predict_proba(X_val)[:, 1])\n","  print(\"AUC-ROC:\", roc_auc_val)\n","\n","  fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n","  roc_auc = auc(fpr, tpr)\n","  print(\"roc_auc\", roc_auc)\n","  result['fpr_val'], result['tpr_val'] = fpr, tpr\n","\n","  y_test_pred = best_model.predict(X_test)\n","  test_accuracy = accuracy_score(y_test, y_test_pred)\n","  print(\"\\nTest Accuracy:\", test_accuracy)\n","  print(\"Test Classification Report:\")\n","  report_test = classification_report(y_test, y_test_pred)\n","  print(report_test)\n","  roc_auc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n","  print(\"AUC-ROC:\", roc_auc_test)\n","\n","  fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n","  roc_auc = auc(fpr, tpr)\n","  result['fpr_test'], result['tpr_test'] = fpr, tpr\n","\n","  result['reg_model'] = 'Logistic Regression'\n","  result['val_accuracy'] = val_accuracy\n","  result['test_accuracy'] = test_accuracy\n","  result['auc_val'] = roc_auc_val\n","  result['auc_test'] = roc_auc_test\n","\n","  result['report_val'] = report_val\n","  result['report_test'] = report_test\n","\n","  result['reg_hyperparameters'] = best_params\n","\n","  return result\n","\n","\"\"\"\n","Fit a random forest model on the graph embeddings at path, for a given topic and decade.\n","Return a results dictionary with metrics saved.\n","\"\"\"\n","def random_forest(path, topic, decade, result={'hyperparameters': {}, 'model': ''}):\n","    df = create_merged_dataset(path, topic, decade)\n","    X = df.drop(columns=['outlet_name', 'label', 'index'])\n","    y = df['label']\n","\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(X)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=126)\n","    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.222, random_state=126)\n","\n","\n","    print(\"------------------------\")\n","    print(\"\\nRANDOM FOREST\\n\")\n","    print(\"------------------------\")\n","    param_grid = {\n","      'n_estimators': [100, 200], # 50,\n","      'max_depth': [None, 10], # 20\n","      'min_samples_split': [2, 5] # 10\n","    }\n","\n","    model = RandomForestClassifier(random_state=126, class_weight='balanced') # tol=1e-4, max_iter=1000\n","    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5) # , n_jobs=-1\n","    grid_search.fit(X_train, y_train)\n","\n","    best_params = grid_search.best_params_\n","    print(\"Best hyperparameters:\", best_params)\n","\n","    best_model = grid_search.best_estimator_\n","\n","    best_model = model.fit(X_train, y_train)\n","\n","    y_val_pred = best_model.predict(X_val)\n","    val_accuracy = accuracy_score(y_val, y_val_pred)\n","    print(\"Validation Accuracy:\", val_accuracy)\n","    print(\"Validation Classification Report:\")\n","    report_val = classification_report(y_val, y_val_pred)\n","    print(report_val)\n","    roc_auc_val = roc_auc_score(y_val, best_model.predict_proba(X_val)[:, 1])\n","    print(\"AUC-ROC:\", roc_auc_val)\n","\n","    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n","    roc_auc = auc(fpr, tpr)\n","    print(\"AUC\", roc_auc)\n","    result['fpr_val'], result['tpr_val'] = fpr, tpr\n","\n","    y_test_pred = best_model.predict(X_test)\n","    test_accuracy = accuracy_score(y_test, y_test_pred)\n","    print(\"\\nTest Accuracy:\", test_accuracy)\n","    print(\"Test Classification Report:\")\n","    report_test = classification_report(y_test, y_test_pred)\n","    print(report_test)\n","    roc_auc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n","    print(\"AUC-ROC:\", roc_auc_test)\n","\n","    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n","    roc_auc = auc(fpr, tpr)\n","    result['fpr_test'], result['tpr_test'] = fpr, tpr\n","\n","    result['reg_model'] = 'Random Forest'\n","    result['val_accuracy'] = val_accuracy\n","    result['test_accuracy'] = test_accuracy\n","    result['auc_val'] = roc_auc_val\n","    result['auc_test'] = roc_auc_test\n","\n","    result['report_val'] = report_val\n","    result['report_test'] = report_test\n","\n","    result['reg_hyperparameters'] = best_params\n","\n","    return result"],"metadata":{"id":"G1zJrIOUhFMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for hidden_size, out_size in sizes:\n","    for temperature in temperatures:\n","        for alpha in alphas:\n","          print(f'\\n===================\\n')\n","          print(f'MODEL {conv}, HIDDEN SIZE {hidden_size}, OUTPUT SIZE {out_size}, TEMPERATURE {temperature}, ALPHA {alpha}')\n","          path = f'karsen_redo/HETEROGNN/{topic}_{decade}{decade+10}/het_{conv}_t{temperature}_a{alpha}_h{hidden_size}_o{out_size}_l{layers}_lr{lr*1000}.pt'\n","          result = {}\n","          result['model'] = conv_map[conv]\n","          result['hyperparameters'] = {'alpha': alpha, 'lr': lr, 'hidden size': hidden_size, 'output size': out_size, 'layers': layers, 'temperature': temperature}\n","          results.append(regression_hetgnn(path, topic, decade, result))\n","\n","          result = {}\n","          result['model'] = conv_map[conv]\n","          result['hyperparameters'] = {'alpha': alpha, 'lr': lr, 'hidden size': hidden_size, 'output size': out_size, 'layers': layers, 'temperature': temperature}\n","          results.append(random_forest(path, topic, decade, result))"],"metadata":{"id":"Oh8CmbC4gX0k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# make table"],"metadata":{"id":"17albnbYK4Sq"}},{"cell_type":"code","source":["\"\"\"\n","Generate a markdown table from the results dictionary outputted from evaluation step.\n","\"\"\"\n","def generate_markdown_table(results):\n","    \"\"\"\n","    Converts results into a Markdown-compatible table.\n","    \"\"\"\n","    headers = [\"Model\", \"Hyperparameters\", \"Regression Model\", \"Validation Accuracy\", \"Validation AUC-ROC\", \"Test Accuracy\", \"Test AUC-ROC\"]\n","    table = f\"## {topic.title()} 19{decade}-19{decade+10} Results\\n| {' | '.join(headers)} |\\n|{'|'.join(['---'] * len(headers))}|\\n\"\n","\n","    for result in results:\n","        reg_model = result['reg_model']\n","        model = result['model']\n","        val_acc = result['val_accuracy']\n","        test_acc = result['test_accuracy']\n","        auc_val = result['auc_val']\n","        auc_test = result['auc_test']\n","        hyperparameters = result[\"hyperparameters\"]\n","\n","        table += f\"| {model} | ```{hyperparameters}``` | {reg_model} | {val_acc:.3f} | {auc_val:.3f} | {test_acc:.3f} | {auc_test:.3f} |\\n\"\n","\n","    return table"],"metadata":{"id":"MCbwqoc_K4_-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["table = generate_markdown_table(results)\n","\n","with open(f'karsen_redo/EVAL/{topic}_{decade}{decade+10}/table_hetero.txt', \"w\") as file:\n","    file.write(table)"],"metadata":{"id":"j9xXtAbuK95d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f'karsen_redo/EVAL/{topic}_{decade}{decade+10}/results_hetero.pkl', \"wb\") as file:\n","    pickle.dump(results, file)"],"metadata":{"id":"W2FKubWJTEh5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Select each best model amongst hyperparameter sets --> final table"],"metadata":{"id":"L9OGwa-HTwDc"}},{"cell_type":"code","source":["\"\"\"\n","Generates separate Markdown tables for each regression model.\n","Each table includes one row per model type, selecting the entry with the highest Validation AUC-ROC for that model type.\n","\"\"\"\n","def final_tables(results):\n","    # Organize results by regression model\n","    reg_model_tables = {}\n","    for result in results:\n","        reg_model = result['reg_model']\n","        if reg_model not in reg_model_tables:\n","            reg_model_tables[reg_model] = []\n","        reg_model_tables[reg_model].append(result)\n","\n","    # Prepare Markdown tables\n","    markdown = f\"## {topic.title()} {decade}-{decade+10} Results\\n\\n\"\n","    headers = [\"Model\", \"Hyperparameters\", \"Validation Accuracy\", \"Validation AUC-ROC\", \"Test Accuracy\", \"Test AUC-ROC\"]\n","    header_row = f\"| {' | '.join(headers)} |\\n|{'|'.join(['---'] * len(headers))}|\\n\"\n","\n","    for reg_model, models in reg_model_tables.items():\n","        # Group models by their model type\n","        grouped_by_model = {}\n","        for model in models:\n","            model_name = model['model']\n","            if model_name not in grouped_by_model:\n","                grouped_by_model[model_name] = []\n","            grouped_by_model[model_name].append(model)\n","\n","        # Select the best result per model type according to ROC-AUC on val set\n","        best_models = [\n","            max(group, key=lambda x: x['auc_val']) for group in grouped_by_model.values()\n","        ]\n","\n","        # Create a table for this regression model\n","        table = f\"### {reg_model} Results\\n\"\n","        table += header_row\n","        for best_model in best_models:\n","            table += (\n","                f\"| {best_model['model']} | ```{best_model['hyperparameters']}``` \"\n","                f\"| {best_model['val_accuracy']:.3f} | {best_model['auc_val']:.3f} \"\n","                f\"| {best_model['test_accuracy']:.3f} | {best_model['auc_test']:.3f} |\\n\"\n","            )\n","        table += \"\\n\"\n","        markdown += table\n","\n","    return markdown"],"metadata":{"id":"D6KeMiMPTvcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reduced_table = final_tables(results)\n","\n","with open(f'karsen_redo/EVAL/{topic}_{decade}{decade+10}/table_hetero_reduced.txt', \"w\") as file:\n","    file.write(reduced_table)"],"metadata":{"id":"xh8bjtxZUf0l","collapsed":true},"execution_count":null,"outputs":[]}]}