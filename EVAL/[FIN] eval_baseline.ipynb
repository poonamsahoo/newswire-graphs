{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This file constructs the baselines using the outlet metadata and runs a logistic regression and random forest classifier to classify newspapers as Republican or Democrat."],"metadata":{"id":"syZABZtZIvjC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9c0D04pfudE"},"outputs":[],"source":["# Imports\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_curve, auc\n","\n","import pickle\n","from google.colab import drive\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","!pip install datasets > /dev/null 2>&1\n","from datasets import load_dataset\n","import pandas as pd\n","from datetime import datetime\n","\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/cs224w_project')"]},{"cell_type":"code","source":["results = []\n","\n","def evaluate_baseline(TOPIC, DECADE):\n","  \"\"\"\n","  Given a topic and decade to analyze, this function evaluates the baselines and runs a logistic regression and random forest classifier to classify newspapers as Republican or Democrat.\n","  It prints the resulting metrics.\n","  \"\"\"\n","  # Clean outlet metadata\n","  outlet_metadata_df = pd.read_pickle(f\"karsen_redo/DATA/outlet_metadata_{DECADE}{DECADE+10}_{TOPIC}.pkl\")\n","  outlet_metadata_df[['latitude', 'longitude']] = pd.DataFrame(outlet_metadata_df['newspaper_coordinates'].tolist())\n","  outlet_metadata_df = outlet_metadata_df.drop(columns='newspaper_coordinates')\n","\n","  # Convert list of embeddings into a bunch of columns\n","  embed_len = len(outlet_metadata_df['avg_embedding'][0])\n","  embeds = pd.DataFrame(outlet_metadata_df['avg_embedding'].tolist(), index=outlet_metadata_df.index).add_prefix('embed')\n","  outlet_metadata_df = pd.concat([outlet_metadata_df, embeds], axis=1)\n","  outlet_metadata_df = outlet_metadata_df.drop(columns=['avg_embedding', 'newspaper_city', 'newspaper_state'])\n","\n","  # Find ground truths\n","  ground_truths = pd.read_pickle(f\"karsen_redo/DATA/clean_ground_truths.pkl\")\n","\n","  merged = pd.merge(outlet_metadata_df, ground_truths, on='outlet_name').dropna() # Drop if no ground truth available\n","  X = merged.drop(columns=['label', 'outlet_name'])\n","  y = merged['label']\n","\n","  scaler = StandardScaler()\n","  X = scaler.fit_transform(X)\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=126)\n","  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.222, random_state=126)\n","  param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],  # regularization strength\n","  }\n","\n","  # REGRESSION\n","  result = {}\n","  model = LogisticRegression(max_iter=1000, class_weight='balanced') # tol=1e-4, max_iter=1000\n","  grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5) # , n_jobs=-1\n","  grid_search.fit(X_train, y_train)\n","\n","  best_params = grid_search.best_params_\n","  print(\"REGRESSION\\n\")\n","  print(\"------------------------\")\n","  print(\"Best hyperparameters:\", best_params)\n","\n","  best_model = grid_search.best_estimator_\n","\n","  best_model = model.fit(X_train, y_train)\n","\n","  y_val_pred = best_model.predict(X_val)\n","  val_accuracy = accuracy_score(y_val, y_val_pred)\n","  print(\"Validation Accuracy:\", val_accuracy)\n","  print(\"Validation Classification Report:\")\n","  report_val = classification_report(y_val, y_val_pred)\n","  print(report_val)\n","  roc_auc_val = roc_auc_score(y_val, best_model.predict_proba(X_val)[:, 1])\n","  print(\"AUC-ROC:\", roc_auc_val)\n","\n","  fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n","  roc_auc = auc(fpr, tpr)\n","  result['fpr_val'], result['tpr_val'] = fpr, tpr\n","\n","  y_test_pred = best_model.predict(X_test)\n","  test_accuracy = accuracy_score(y_test, y_test_pred)\n","  print(\"\\nTest Accuracy:\", test_accuracy)\n","  print(\"Test Classification Report:\")\n","  report_test = classification_report(y_test, y_test_pred)\n","  print(report_test)\n","  roc_auc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n","  print(\"AUC-ROC:\", roc_auc_test)\n","\n","  fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n","  roc_auc = auc(fpr, tpr)\n","  result['fpr_test'], result['tpr_test'] = fpr, tpr\n","\n","  result['hyperparameters'] = {}\n","  result['model'] = 'Raw Input Features (Baseline)'\n","  result['reg_model'] = 'Logistic Regression'\n","  result['val_accuracy'] = val_accuracy\n","  result['test_accuracy'] = test_accuracy\n","  result['auc_val'] = roc_auc_val\n","  result['auc_test'] = roc_auc_test\n","\n","  result['report_val'] = report_val\n","  result['report_test'] = report_test\n","\n","  result['reg_hyperparameters'] = best_params\n","\n","  results.append(result)\n","\n","  # RANDOM FOREST\n","  print(\"------------------------\")\n","  print(\"\\nRANDOM FOREST\\n\")\n","  print(\"------------------------\")\n","  param_grid = {\n","    'n_estimators': [100, 200], # 50,\n","    'max_depth': [None, 10], # 20\n","    'min_samples_split': [2, 5] # 10\n","  }\n","\n","  result = {}\n","  model = RandomForestClassifier(random_state=126, class_weight='balanced') # tol=1e-4, max_iter=1000\n","  grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5) # , n_jobs=-1\n","  grid_search.fit(X_train, y_train)\n","\n","  best_params = grid_search.best_params_\n","  print(\"Best hyperparameters:\", best_params)\n","\n","  best_model = grid_search.best_estimator_\n","\n","  best_model = model.fit(X_train, y_train)\n","\n","  y_val_pred = best_model.predict(X_val)\n","  val_accuracy = accuracy_score(y_val, y_val_pred)\n","  print(\"Validation Accuracy:\", val_accuracy)\n","  print(\"Validation Classification Report:\")\n","  report_val = classification_report(y_val, y_val_pred)\n","  print(report_val)\n","  roc_auc_val = roc_auc_score(y_val, best_model.predict_proba(X_val)[:, 1])\n","  print(\"AUC-ROC:\", roc_auc_val)\n","\n","  fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n","  roc_auc = auc(fpr, tpr)\n","  result['fpr_val'], result['tpr_val'] = fpr, tpr\n","\n","  y_test_pred = best_model.predict(X_test)\n","  test_accuracy = accuracy_score(y_test, y_test_pred)\n","  print(\"\\nTest Accuracy:\", test_accuracy)\n","  print(\"Test Classification Report:\")\n","  report_test = classification_report(y_test, y_test_pred)\n","  print(report_test)\n","  roc_auc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n","  print(\"AUC-ROC:\", roc_auc_test)\n","\n","  fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n","  roc_auc = auc(fpr, tpr)\n","  result['fpr_test'], result['tpr_test'] = fpr, tpr\n","\n","  result['hyperparameters'] = {}\n","  result['model'] = 'Raw Input Features (Baseline)'\n","  result['reg_model'] = 'Random Forest'\n","  result['val_accuracy'] = val_accuracy\n","  result['test_accuracy'] = test_accuracy\n","  result['auc_val'] = roc_auc_val\n","  result['auc_test'] = roc_auc_test\n","\n","  result['report_val'] = report_val\n","  result['report_test'] = report_test\n","\n","  result['reg_hyperparameters'] = best_params\n","\n","  results.append(result)\n","\n","  return results"],"metadata":{"id":"H9IxnvJrfv2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Edit below to dump the results into a pickle file, depending on which topic-decade.\n","\"\"\"\n","TOPIC = 'macro'\n","DECADE = 60\n","results = []\n","results = evaluate_baseline(TOPIC, DECADE)\n","\n","folder_name = f\"karsen_redo/EVAL/{TOPIC}_{DECADE}{DECADE+10}\"\n","if not os.path.exists(folder_name):\n","    os.makedirs(folder_name)\n","\n","with open(f'karsen_redo/EVAL/{TOPIC}_{DECADE}{DECADE+10}/results_baseline.pkl', \"wb\") as file:\n","    pickle.dump(results, file)"],"metadata":{"id":"kWTXhY3dkLDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_markdown_table(results):\n","    \"\"\"\n","    Converts results into a Markdown-compatible table.\n","    \"\"\"\n","    headers = [\"Model\", \"Hyperparameters\", \"Regression Model\", \"Validation Accuracy\", \"Validation AUC-ROC\", \"Test Accuracy\", \"Test AUC-ROC\"]\n","    table = f\"## {TOPIC.title()} 19{DECADE} - 19{DECADE+10} Results\\n| {' | '.join(headers)} |\\n|{'|'.join(['---'] * len(headers))}|\\n\"\n","\n","    for result in results:\n","        reg_model = result['reg_model']\n","        model = result['model']\n","        val_acc = result['val_accuracy']\n","        test_acc = result['test_accuracy']\n","        auc_val = result['auc_val']\n","        auc_test = result['auc_test']\n","        hyperparameters = result[\"hyperparameters\"]\n","\n","        table += f\"| {model} | ```{hyperparameters}``` | {reg_model} | {val_acc:.3f} | {auc_val:.3f} | {test_acc:.3f} | {auc_test:.3f} |\\n\"\n","\n","    return table"],"metadata":{"id":"AU0eCe-QZ9ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Writes the markdown table as needed.\n","\"\"\"\n","table = generate_markdown_table(results)\n","\n","with open(f'karsen_redo/EVAL/{TOPIC}_{DECADE}{DECADE+10}/table_baseline.txt', \"w\") as file:\n","    file.write(table)"],"metadata":{"id":"dZnsVglvaB0t"},"execution_count":null,"outputs":[]}]}